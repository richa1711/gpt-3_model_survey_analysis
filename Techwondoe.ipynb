{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+R2dg6cxNL4wIKzyqwrTY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/richa1711/gpt-3_model_survey_analysis/blob/main/Techwondoe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "S0sY5vKmmEQq",
        "outputId": "ff8bd515-9923-4766-b39c-3f2c216b1650"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.9/dist-packages (0.27.2)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (4.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import openai\n",
        "import re\n",
        "\n",
        "# Set up OpenAI API credentials\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "# Prepare the training dataset\n",
        "training_questions = [\n",
        "  \"What is the product's main feature?\",\n",
        "  \"How does the product compare to similar products in the market?\",\n",
        "  \"What are the benefits of using the product?\",\n",
        "  \"What are the drawbacks of using the product?\",\n",
        "  \"How user-friendly is the product?\",\n",
        "  \"What kind of customer support is provided for the product?\",\n",
        "  \"How does the product handle data privacy and security?\",\n",
        "  \"What kind of customization options are available for the product?\",\n",
        "]\n",
        "\n",
        "training_answers = [\n",
        "  \"The product's main feature is its robust computing and advanced computing options\",\n",
        "  \"Compared to similar products in the market, our product stands out because it provides new technology built in feature \",\n",
        "  \"Using our product has several benefits, including premium serives and speed \",\n",
        "  \"One of the main drawbacks of using our product being it does not provide python language compiler\",\n",
        "  \"Our product is designed to be very user-friendly\",\n",
        "  \"We offer several customer support options, including 24/7 call service and home delivery\",\n",
        "  \"Data privacy and security are very important to us, which is why our product stands out from others\",\n",
        "  \"Our product offers several customization options\",\n",
        "]\n",
        "\n",
        "summary_paragraph = \"Our product is a powerful solution for its robust computing and advanced computing options, offering several benefits over similar products in the market. Although there are some drawbacks such as it does not provide python compiler, we have designed it to be very user-friendly and offer excellent customer support. we have made data privacy and security a top priority. In addition, our product offers several customization options \"\n",
        "\n",
        "# Combine the training data into a single string\n",
        "training_data = \"\\n\".join([f\"Q: {q}\\nA: {a}\" for q, a in zip(training_questions, training_answers)])\n",
        "prompt = f\"Fine-tune the GPT-3 model on the following training data:\\n\\n{training_data}\\nSummary: {summary_paragraph}\\n\\n\"\n",
        "model = \"text-davinci-002\"\n",
        "fine_tuned_model = openai.Completion.create(\n",
        "    engine=model,\n",
        "    prompt=prompt,\n",
        "    max_tokens=1026,\n",
        "    n=1,\n",
        "    stop=None,\n",
        "    temperature=0.5,\n",
        ")\n",
        "\n",
        "testing_questions = [  \"How was the quality of the food?\",  \"How was the service provided by the staff?\",  \"Did you find the restaurant's atmosphere pleasant?\",  \"Was the pricing of the food reasonable?\",  \"Would you recommend the restaurant to others?\",  \"Did the restaurant meet your expectations?\"]\n",
        "\n",
        "testing_answers = [  \"The quality of the food was excellent and exceeded my expectations.\",  \"The service provided by the staff was prompt and attentive.\",  \"The restaurant's atmosphere was pleasant and created a comfortable dining experience.\",  \"The pricing of the food was reasonable and good value for the money.\",  \"I would definitely recommend the restaurant to others.\",  \"The restaurant met my expectations and I had a great overall experience.\"]\n",
        "testing_data = \"\\n\".join([f\"Q: {q}\\nA: {a}\" for q, a in zip(testing_questions, testing_answers)])\n",
        "\n",
        "test_data = testing_data\n",
        "# Generate a paragraph summarizing the product details based on the testing dataset\n",
        "prompt3 = f\"sentimental analysis about the product been discussed in the dataset:\\n\\n{test_data}\\n\\n\"\n",
        "prompt2 = f\"Brielfy discuss about what is going on in the following survey and what are the customers views and sentimental analysis :\\n\\n{test_data}\\n\\n\"\n",
        "\n",
        "# prompt = f\"Positive and negative analysis in the dataset:\\n\\n{test_data}\\n\\n\"\n",
        "prompt1= f\"Give suitable suggestions for improvement of the service by analysing the following dataset of survey:\\n\\n{test_data}\\n\\n\"\n",
        "\n",
        "#creating a list of all the prompts/contextual summary we want to get from the model\n",
        "prompts = [prompt1, prompt2, prompt3]\n",
        "for prompt in prompts:\n",
        "  response = openai.Completion.create(\n",
        "    engine=fine_tuned_model.model,\n",
        "    prompt=prompt,\n",
        "    max_tokens=1027,\n",
        "    n=1,\n",
        "    stop=None,\n",
        "    temperature=0.5,\n",
        "  )\n",
        "\n",
        "  result = response.choices[0].text\n",
        "# try:\n",
        "#   insights = re.search(r\"Summary:(.*)\", result).group(1)\n",
        "# except:\n",
        "#   insights = re.search(r\"Summary:(.*)\", result)\n",
        "\n",
        "  print(\"Product Details Summary:\", result)\n",
        "  print()"
      ],
      "metadata": {
        "id": "jWn0HuRBIb_P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "189ff573-d127-4fdd-b3fb-d7caf140e119"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Product Details Summary: \n",
            "There are a few things that could be improved with the restaurant:\n",
            "\n",
            "-The quality of the food could be even better\n",
            "-The staff could be more attentive\n",
            "-The restaurant's atmosphere could be more inviting\n",
            "-The pricing could be even more reasonable\n",
            "\n",
            "Product Details Summary: \n",
            "The customers views and sentimental analysis of the survey are positive. The customers are happy with the quality of the food, the service provided by the staff, the pricing of the food, and the overall experience.\n",
            "\n",
            "Product Details Summary: \n",
            "Overall, it seems that the sentiment in the dataset is quite positive. The quality of the food and service are both praised, and the atmosphere is said to be pleasant. The pricing is also deemed to be reasonable. Overall, it seems that the restaurant is highly recommended.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}